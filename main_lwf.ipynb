{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_lwf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielegenta/ArtReader/blob/master/main_lwf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Cpfl5JiceY",
        "colab_type": "code",
        "outputId": "54b2aee1-26af-4b28-826d-da7fd697c8a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "  Following the iCaRL paper specifications,\n",
        "  LwF is implemented simirality to iCaRL itself.\n",
        "  The differences are:\n",
        "  - No exemplars management\n",
        "  - For classification, it is used the network output values themselves\n",
        "  (ref. iCaRL paper section 4.1)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  Following the iCaRL paper specifications,\\n  LwF is implemented simirality to iCaRL itself.\\n  The differences are:\\n  - No exemplars management\\n  - For classification, it is used the network output values themselves\\n  (ref. iCaRL paper section 4.1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhl89o9xjPsT",
        "colab_type": "code",
        "outputId": "2d352475-207f-4d7f-bffd-b4df2b575aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juvZ4mFgjZ8t",
        "colab_type": "code",
        "outputId": "6ac0acb8-8d10-4401-d726-42b681f9f2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "#!rm -r $DATA_DIR\n",
        "#!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/danielegenta/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 602 (delta 61), reused 63 (delta 29), pack-reused 502\u001b[K\n",
            "Receiving objects: 100% (602/602), 4.03 MiB | 502.00 KiB/s, done.\n",
            "Resolving deltas: 100% (347/347), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmqlWIxXjldh",
        "colab_type": "code",
        "outputId": "fa62de9b-6637-4a66-adda-f2873c64dbad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-27 09:03:42--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  13.8MB/s    in 13s     \n",
            "\n",
            "2020-05-27 09:03:56 (12.4 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n",
            "mv: cannot move 'cifar-100-python' to 'DATA/cifar-100-python/cifar-100-python': Directory not empty\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-LUNWGgSYwm",
        "colab_type": "code",
        "outputId": "39099270-89aa-4c35-bf3f-145e0fff7918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from Cifar100 import utils\n",
        "\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = dictHyperparams[\"LR\"]          # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = dictHyperparams[\"SEED\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 30, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKXMsUQ2oPS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8xM_JUJoP-l",
        "colab_type": "code",
        "outputId": "8440eed8-0510-4a4d-b68b-6cf4029c81fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owLONCmOoZUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ONNgtszoa26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlDVHznwocr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2J8c2SaohuJ",
        "colab_type": "text"
      },
      "source": [
        "**LWF implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7fwVxB7oefq",
        "colab_type": "code",
        "outputId": "dcc606a2-d394-4dc2-cc35-d2192bf9a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# default params\n",
        "from Cifar100.lwf_model import LWF\n",
        "\n",
        "feature_size = 2048\n",
        "n_classes = 0\n",
        "lwf = LWF(feature_size, n_classes, BATCH_SIZE, WEIGHT_DECAY, LR, GAMMA, NUM_EPOCHS, DEVICE,MILESTONES,MOMENTUM, outputs_labels_mapping)\n",
        "lwf.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LWF(\n",
              "  (feature_extractor): ResNet(\n",
              "    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (2): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (3): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (4): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
              "    (fc): Linear(in_features=64, out_features=2048, bias=True)\n",
              "  )\n",
              "  (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "  (ReLU): ReLU()\n",
              "  (fc): Linear(in_features=2048, out_features=0, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4l0ELnTxI2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H60xMfbW2R3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def incrementalTraining(net, train_subsets, val_subsets, test_subsets,eval_transform, reverse_index):\n",
        "    #groups_accuracies=[] not used right now, use it if you want test on single groups\n",
        "    all_accuracies = []\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "    group_id=1\n",
        "    test_set = None\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      print(\"GROUP: \",group_id)\n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "      train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "      val_dataloader = DataLoader(val_subset, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "      test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE,shuffle=True, num_workers=4)\n",
        "      \n",
        "      #net.train()\n",
        "\n",
        "      new_classes_examined = list(train_dataset.df.loc[train_subset.indices, 'labels'].value_counts().index)\n",
        "\n",
        "      # update representation\n",
        "      net.update_representation(train_subset, new_classes_examined)\n",
        "\n",
        "      # evaluation on the train set\n",
        "      net.eval()\n",
        "      total = 0.0\n",
        "      correct = 0.0\n",
        "\n",
        "      for indices, images, labels in train_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        labels = reverse_index.getNodes(labels)\n",
        "        preds = net.classify(images)\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # train Accuracy\n",
        "      print ('Train Accuracy (on current group): %.2f\\n' % (100.0 * correct / len(train_subset)))\n",
        "      \n",
        "      # validation on current group\n",
        "      #net.eval()\n",
        "      total = 0.0\n",
        "      correct = 0.0\n",
        "\n",
        "      for indices, images, labels in val_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        labels = reverse_index.getNodes(labels)\n",
        "        preds = net.classify(images)\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "      # val Accuracy\n",
        "      print ('Val Accuracy (on current group): %.2f\\n' % (100.0 * correct / len(val_subset)))\n",
        "\n",
        "      # evaluation on all the previous groups\n",
        "      #net.eval()\n",
        "      total = 0.0\n",
        "      correct = 0.0\n",
        "\n",
        "      for indices, images, labels in test_dataloader:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        #labels_enc = utils._one_hot_encode(labels, net.n_classes, reverse_index)\n",
        "        labels = reverse_index.getNodes(labels)\n",
        "        preds = net.classify(images)\n",
        "        correct += torch.sum(preds == labels.data).data.item()\n",
        "      \n",
        "      all_preds_cm.extend(preds.tolist())\n",
        "      all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "      accuracy = correct / len(test_set)\n",
        "      all_accuracies.append(accuracy)\n",
        "      # Train Accuracy\n",
        "      print ('Test Accuracy (all groups seen so far): %.2f\\n' % (100.0 * accuracy))\n",
        "\n",
        "      net.n_known = net.n_classes\n",
        "      print (\"the model knows %d classes:\\n \" % net.n_known)\n",
        "\n",
        "      group_id+=1\n",
        "    \n",
        "    return all_accuracies, np.array(all_preds_cm), np.array(all_labels_cm)\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TXVwGceM6gN",
        "colab_type": "code",
        "outputId": "124b7b1e-2cbc-4184-a848-3da44e3e137f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "accuracies, all_preds_cm, all_labels_cm = incrementalTraining(lwf, train_subsets, val_subsets, test_subsets,eval_transform, outputs_labels_mapping)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2779, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2616, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2301, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2283, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2110, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2138, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2264, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1887, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1818, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1703, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1665, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1667, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1731, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1353, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1318, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1348, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1347, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1244, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1328, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1089, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1305, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1362, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1218, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1137, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1214, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1117, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1241, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1341, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1205, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1148, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.0892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.0953, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1034, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.0716, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.0983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.0845, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.0897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.0685, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.0614, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.0679, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.0756, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.0829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.0521, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.0533, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.0530, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.0567, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.0579, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.0447, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.0494, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.0539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.0645, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.0385, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.0304, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.0349, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.0491, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.0367, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.0319, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.0238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.0381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.0441, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.0253, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.0224, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.0265, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 97.70\n",
            "\n",
            "Val Accuracy (on current group): 82.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 81.60\n",
            "\n",
            "the model knows 10 classes:\n",
            " \n",
            "GROUP:  2\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2344, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2160, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2039, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1744, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1754, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1714, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1664, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1637, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1643, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1723, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1655, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1573, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1693, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1493, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1583, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1463, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1443, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1419, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1572, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1545, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1517, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1477, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1460, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1364, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1394, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1584, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1423, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1450, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1447, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1444, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1407, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1503, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1411, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1409, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1350, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1434, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1333, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1358, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1354, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1275, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1292, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1323, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1321, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1343, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1270, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1435, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1381, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1257, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1249, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1294, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1289, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1352, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1277, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 62.55\n",
            "\n",
            "Val Accuracy (on current group): 52.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 64.65\n",
            "\n",
            "the model knows 20 classes:\n",
            " \n",
            "GROUP:  3\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.1914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.1957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.1846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.1874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1792, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1743, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1725, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1697, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1733, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1771, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1747, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1666, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1719, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1687, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1703, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1675, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1712, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1679, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1668, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1728, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1620, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1559, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1647, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1656, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1701, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1631, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1599, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1606, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1653, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1654, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1594, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1724, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1593, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1623, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1528, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1610, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1662, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1626, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1657, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1574, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1603, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1630, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1627, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1610, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1569, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1613, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1634, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1622, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1585, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1571, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1579, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1612, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1551, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1538, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1495, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1508, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1708, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1546, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1618, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1516, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1500, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1539, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1578, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 43.70\n",
            "\n",
            "Val Accuracy (on current group): 48.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 48.10\n",
            "\n",
            "the model knows 30 classes:\n",
            " \n",
            "GROUP:  4\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2238, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2129, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.1937, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.1925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1859, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1898, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1938, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1895, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1858, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1855, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1848, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1817, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1829, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1865, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1834, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1870, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1863, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1839, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1782, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1838, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1847, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1813, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1762, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1828, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1820, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1760, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1816, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1814, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1808, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1806, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1789, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1784, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1783, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1748, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1824, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1769, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1853, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1800, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1727, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1856, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1801, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1774, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1768, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1812, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1795, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1797, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1759, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1785, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1805, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1758, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1777, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1766, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 40.30\n",
            "\n",
            "Val Accuracy (on current group): 44.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 39.95\n",
            "\n",
            "the model knows 40 classes:\n",
            " \n",
            "GROUP:  5\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2188, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2152, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1986, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2027, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.1964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2030, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.2002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1899, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1914, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1880, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1897, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1924, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1918, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1892, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1874, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1926, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1846, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1909, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1910, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1905, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1984, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1930, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1869, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1896, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1861, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 28.44\n",
            "\n",
            "Val Accuracy (on current group): 32.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 34.00\n",
            "\n",
            "the model knows 50 classes:\n",
            " \n",
            "GROUP:  6\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2047, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2042, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2057, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.1979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.1997, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.1993, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.1959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1962, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1906, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1872, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1901, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1891, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1875, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1894, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1902, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1969, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1940, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1900, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1915, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1904, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1903, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1912, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1971, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1908, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1890, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.1927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1946, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1933, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1879, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1873, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1934, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1936, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1836, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1886, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1819, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 23.43\n",
            "\n",
            "Val Accuracy (on current group): 26.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 29.45\n",
            "\n",
            "the model knows 60 classes:\n",
            " \n",
            "GROUP:  7\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2200, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2095, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2100, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2066, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.1999, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.1991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.2040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.2009, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.2021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2035, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.2033, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.2073, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.2023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1929, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1959, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.2020, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1974, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1922, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1925, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1947, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.2016, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1939, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1917, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.2003, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1972, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1954, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1919, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.1945, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1957, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1935, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1979, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1977, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1910, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 30.77\n",
            "\n",
            "Val Accuracy (on current group): 28.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 26.23\n",
            "\n",
            "the model knows 70 classes:\n",
            " \n",
            "GROUP:  8\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2193, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2091, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2064, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2041, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.2131, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.2001, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.2014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2031, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1931, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.2010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.2054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.2012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.2063, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.2045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1944, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.2019, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.1987, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.1981, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.1961, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.1980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.1985, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.1916, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.2004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.2021, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.1948, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.2046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.2037, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.2026, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.2017, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.2012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1966, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1968, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1928, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.2004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1994, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.2008, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1942, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.1950, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.1983, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 33.82\n",
            "\n",
            "Val Accuracy (on current group): 36.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 24.94\n",
            "\n",
            "the model knows 80 classes:\n",
            " \n",
            "GROUP:  9\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2212, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2194, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2091, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2082, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2071, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2004, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2051, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2032, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.2101, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.2045, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.2014, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.2040, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2023, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.1952, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2006, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.1990, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.1973, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.1995, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.2011, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.2018, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.2010, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.2007, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.1964, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.1951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.1992, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.2053, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.1960, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.2002, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.1988, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.2065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.2069, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.2036, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.2012, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.2046, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.1980, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.1958, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.1963, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.1982, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.2048, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.1991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.1967, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.1920, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.1989, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.2013, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.2038, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.2015, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.1998, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.1943, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.1951, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.2000, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.1996, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.1975, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.1991, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.1927, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.1970, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.2060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.2005, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.1965, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 22.69\n",
            "\n",
            "Val Accuracy (on current group): 30.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 22.94\n",
            "\n",
            "the model knows 90 classes:\n",
            " \n",
            "GROUP:  10\n",
            "NUM_EPOCHS:  0 / 70\n",
            "LOSS:  tensor(0.2230, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  1 / 70\n",
            "LOSS:  tensor(0.2198, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  2 / 70\n",
            "LOSS:  tensor(0.2191, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  3 / 70\n",
            "LOSS:  tensor(0.2166, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  4 / 70\n",
            "LOSS:  tensor(0.2143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  5 / 70\n",
            "LOSS:  tensor(0.2181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  6 / 70\n",
            "LOSS:  tensor(0.2116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  7 / 70\n",
            "LOSS:  tensor(0.2120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  8 / 70\n",
            "LOSS:  tensor(0.2171, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  9 / 70\n",
            "LOSS:  tensor(0.2181, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  10 / 70\n",
            "LOSS:  tensor(0.2134, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  11 / 70\n",
            "LOSS:  tensor(0.2111, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  12 / 70\n",
            "LOSS:  tensor(0.2114, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  13 / 70\n",
            "LOSS:  tensor(0.2170, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  14 / 70\n",
            "LOSS:  tensor(0.2126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  15 / 70\n",
            "LOSS:  tensor(0.2133, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  16 / 70\n",
            "LOSS:  tensor(0.2140, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  17 / 70\n",
            "LOSS:  tensor(0.2156, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  18 / 70\n",
            "LOSS:  tensor(0.2118, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  19 / 70\n",
            "LOSS:  tensor(0.2102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  20 / 70\n",
            "LOSS:  tensor(0.2081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  21 / 70\n",
            "LOSS:  tensor(0.2090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  22 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  23 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  24 / 70\n",
            "LOSS:  tensor(0.2123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  25 / 70\n",
            "LOSS:  tensor(0.2104, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  26 / 70\n",
            "LOSS:  tensor(0.2128, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  27 / 70\n",
            "LOSS:  tensor(0.2105, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  28 / 70\n",
            "LOSS:  tensor(0.2070, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  29 / 70\n",
            "LOSS:  tensor(0.2126, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  30 / 70\n",
            "LOSS:  tensor(0.2083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  31 / 70\n",
            "LOSS:  tensor(0.2090, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  32 / 70\n",
            "LOSS:  tensor(0.2097, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  33 / 70\n",
            "LOSS:  tensor(0.2144, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  34 / 70\n",
            "LOSS:  tensor(0.2094, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  35 / 70\n",
            "LOSS:  tensor(0.2091, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  36 / 70\n",
            "LOSS:  tensor(0.2077, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  37 / 70\n",
            "LOSS:  tensor(0.2103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  38 / 70\n",
            "LOSS:  tensor(0.2072, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  39 / 70\n",
            "LOSS:  tensor(0.2086, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  40 / 70\n",
            "LOSS:  tensor(0.2119, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  41 / 70\n",
            "LOSS:  tensor(0.2087, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  42 / 70\n",
            "LOSS:  tensor(0.2067, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  43 / 70\n",
            "LOSS:  tensor(0.2123, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  44 / 70\n",
            "LOSS:  tensor(0.2093, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  45 / 70\n",
            "LOSS:  tensor(0.2076, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  46 / 70\n",
            "LOSS:  tensor(0.2120, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  47 / 70\n",
            "LOSS:  tensor(0.2074, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  48 / 70\n",
            "LOSS:  tensor(0.2054, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  49 / 70\n",
            "LOSS:  tensor(0.2076, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  50 / 70\n",
            "LOSS:  tensor(0.2143, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  51 / 70\n",
            "LOSS:  tensor(0.2084, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  52 / 70\n",
            "LOSS:  tensor(0.2059, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  53 / 70\n",
            "LOSS:  tensor(0.2102, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  54 / 70\n",
            "LOSS:  tensor(0.2088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  55 / 70\n",
            "LOSS:  tensor(0.2096, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  56 / 70\n",
            "LOSS:  tensor(0.2062, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  57 / 70\n",
            "LOSS:  tensor(0.2078, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  58 / 70\n",
            "LOSS:  tensor(0.2075, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  59 / 70\n",
            "LOSS:  tensor(0.2116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  60 / 70\n",
            "LOSS:  tensor(0.2065, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  61 / 70\n",
            "LOSS:  tensor(0.2083, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  62 / 70\n",
            "LOSS:  tensor(0.2099, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  63 / 70\n",
            "LOSS:  tensor(0.2060, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  64 / 70\n",
            "LOSS:  tensor(0.2103, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  65 / 70\n",
            "LOSS:  tensor(0.2081, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  66 / 70\n",
            "LOSS:  tensor(0.2079, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  67 / 70\n",
            "LOSS:  tensor(0.2116, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  68 / 70\n",
            "LOSS:  tensor(0.2088, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "NUM_EPOCHS:  69 / 70\n",
            "LOSS:  tensor(0.2085, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
            "Train Accuracy (on current group): 25.56\n",
            "\n",
            "Val Accuracy (on current group): 18.00\n",
            "\n",
            "Test Accuracy (all groups seen so far): 21.52\n",
            "\n",
            "the model knows 100 classes:\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBpsSTfGNM1Y",
        "colab_type": "code",
        "outputId": "bb10abac-1850-406e-b4bd-77e65a7ec5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# metrics\n",
        "method = 'LwF'\n",
        "\n",
        "print(\"metrics LWF for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "# accuracy \n",
        "data_plot_line=[]\n",
        "\n",
        "classes_per_group = 10\n",
        "for group_classes in range(0,10):\n",
        "    data_plot_line.append(((group_classes + 1)*classes_per_group, accuracies[group_classes]))\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write to JSON file\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "metrics FINETUNING for seed 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5fAa7hPWbE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}